{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from counterfactuals.datasets.blobs import BlobsDataset\n",
    "from counterfactuals.cf_methods.ppcef import PPCEF\n",
    "from counterfactuals.losses import MulticlassDiscLoss\n",
    "from counterfactuals.discriminative_models import MultinomialLogisticRegression\n",
    "from counterfactuals.generative_models import MaskedAutoregressiveFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_distribution(model):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(20, 12)\n",
    "\n",
    "    xline = torch.linspace(-0.1, 1.2, 200)\n",
    "    yline = torch.linspace(-0.1, 1.2, 200)\n",
    "    xgrid, ygrid = torch.meshgrid(xline, yline)\n",
    "    xyinput = torch.cat([xgrid.reshape(-1, 1), ygrid.reshape(-1, 1)], dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        zgrid0 = model(xyinput, torch.zeros(40000, 1)).exp().reshape(200, 200)\n",
    "        zgrid1 = model(xyinput, torch.ones(40000, 1)).exp().reshape(200, 200)\n",
    "        zgrid2 = model(xyinput, 2*torch.ones(40000, 1)).exp().reshape(200, 200)\n",
    "\n",
    "    zgrid0 = zgrid0.numpy()\n",
    "    zgrid1 = zgrid1.numpy()\n",
    "    zgrid2 = zgrid2.numpy()\n",
    "\n",
    "    _ = ax.contour(\n",
    "        xgrid.numpy(),\n",
    "        ygrid.numpy(),\n",
    "        zgrid0,\n",
    "        levels=10,\n",
    "        cmap=\"Greys\",\n",
    "        linewidths=0.4,\n",
    "        antialiased=True,\n",
    "    )\n",
    "    _ = ax.contour(\n",
    "        xgrid.numpy(),\n",
    "        ygrid.numpy(),\n",
    "        zgrid1,\n",
    "        levels=10,\n",
    "        cmap=\"Oranges\",\n",
    "        linewidths=0.4,\n",
    "        antialiased=True,\n",
    "    )\n",
    "    _ = ax.contour(\n",
    "        xgrid.numpy(),\n",
    "        ygrid.numpy(),\n",
    "        zgrid2,\n",
    "        levels=10,\n",
    "        cmap=\"Blues\",\n",
    "        linewidths=0.4,\n",
    "        antialiased=True,\n",
    "    )\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metrics_textbox(metrics_series, ax):\n",
    "    text_str = '\\n'.join(f\"{metric}: {value:.3f}\" for metric, value in metrics_series.items())\n",
    "\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.7)\n",
    "    ax.text(0.05, 0.95, text_str, transform=ax.transAxes, fontsize=10, \n",
    "            verticalalignment='top', bbox=props)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_all_cf(disc_model, flow, X_test, X_cf, metrics):\n",
    "    assert X_test.shape[1] == X_cf.shape[1], \"Sizes of test set and counterfactuals is not equal.\"\n",
    "\n",
    "    ax = plot_model_distribution(flow)\n",
    "\n",
    "    num_classes = list(disc_model.parameters())[0].shape[0]\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        # Classifier Line\n",
    "        w1, w2 = list(disc_model.parameters())[0][i].detach().cpu().numpy()\n",
    "        b = list(disc_model.parameters())[1][i].detach().cpu().numpy().item()\n",
    "        c = -b / w2\n",
    "        m = -w1 / w2\n",
    "        xmin, xmax = -0.1, 1.2\n",
    "        ymin, ymax = -0.1, 1.2\n",
    "        xd = np.array([xmin, xmax])\n",
    "        yd = m * xd + c\n",
    "        plt.plot(xd, yd, \"red\", lw=2.0, ls=\"dashed\")\n",
    "        # plt.axis(\"off\")\n",
    "    \n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=matplotlib.colormaps[\"tab10\"], s=50, alpha=0.8)\n",
    "    ax.scatter(X_cf[:, 0], X_cf[:, 1], c=\"orange\", s=50, alpha=0.8)\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        ax.arrow(\n",
    "            X_test[i, 0],\n",
    "            X_test[i, 1],\n",
    "            X_cf[i, 0] - X_test[i, 0],\n",
    "            X_cf[i, 1] - X_test[i, 1],\n",
    "            width=0.001,\n",
    "            lw=0.001,\n",
    "            length_includes_head=True,\n",
    "            alpha=0.5,\n",
    "            color=\"k\",\n",
    "        )\n",
    "\n",
    "    ax = add_metrics_textbox(metrics, ax)\n",
    "    \n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 artelth20\n",
      "(300, 2) (300, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/counterfactuals/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cbce\n",
      "(300, 2) (300, 2)\n",
      "0 CEM\n",
      "(300, 2) (300, 2)\n",
      "0 ppcef\n",
      "(300, 2) (300, 2)\n",
      "0 wach\n",
      "(300, 2) (300, 2)\n",
      "1 artelth20\n",
      "(300, 2) (300, 2)\n",
      "1 cbce\n",
      "(300, 2) (300, 2)\n",
      "1 CEM\n",
      "(300, 2) (300, 2)\n",
      "1 ppcef\n",
      "(300, 2) (300, 2)\n",
      "1 wach\n",
      "(300, 2) (300, 2)\n",
      "2 artelth20\n",
      "(300, 2) (300, 2)\n",
      "2 cbce\n",
      "(300, 2) (300, 2)\n",
      "2 CEM\n",
      "(300, 2) (300, 2)\n",
      "2 ppcef\n",
      "(300, 2) (300, 2)\n",
      "2 wach\n",
      "(300, 2) (300, 2)\n",
      "3 artelth20\n",
      "(300, 2) (300, 2)\n",
      "3 cbce\n",
      "(300, 2) (300, 2)\n",
      "3 CEM\n",
      "(300, 2) (300, 2)\n",
      "3 ppcef\n",
      "(300, 2) (300, 2)\n",
      "3 wach\n",
      "(300, 2) (300, 2)\n",
      "4 artelth20\n",
      "(299, 2) (299, 2)\n",
      "4 cbce\n",
      "(299, 2) (299, 2)\n",
      "4 CEM\n",
      "(299, 2) (299, 2)\n",
      "4 ppcef\n",
      "(299, 2) (299, 2)\n",
      "4 wach\n",
      "(299, 2) (299, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset = BlobsDataset(file_path=\"../data/blobs.csv\")\n",
    "datasets = iter(dataset.get_cv_splits())\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = next(datasets)  # yields splits one by one\n",
    "    \n",
    "    disc_model = MultinomialLogisticRegression(dataset.X_train.shape[1], len(np.unique(dataset.y)))\n",
    "    disc_model.load(f\"../models/BlobsDataset/disc_model_{i}_MultinomialLogisticRegression.pt\")\n",
    "    \n",
    "    flow = MaskedAutoregressiveFlow(\n",
    "        dataset.X_train.shape[1],\n",
    "        hidden_features=4,\n",
    "        num_blocks_per_layer=2,\n",
    "        num_layers=5,\n",
    "        context_features=1,\n",
    "    )\n",
    "    flow.load(f\"../models/BlobsDataset/gen_model_{i}_MaskedAutoregressiveFlow.pt\")\n",
    "    \n",
    "    cf = PPCEF(\n",
    "        gen_model=flow,\n",
    "        disc_model=disc_model,\n",
    "        disc_model_criterion=MulticlassDiscLoss(),\n",
    "        neptune_run=None,\n",
    "    )\n",
    "    \n",
    "    median_prob = (\n",
    "        flow.predict_log_prob(dataset.train_dataloader(batch_size=64, shuffle=False))\n",
    "        .median()\n",
    "        .item()\n",
    "    )\n",
    "\n",
    "    for method in ['artelth20', 'cbce', 'CEM', 'ppcef', 'wach']: # 'CEGP'\n",
    "        X_cf = pd.read_csv(\n",
    "            f\"../models/BlobsDataset/{method}/counterfactuals_MultinomialLogisticRegression_{i}.csv\"\n",
    "        ).values\n",
    "        \n",
    "        metrics = pd.read_csv(\n",
    "            f\"../models/BlobsDataset/{method}/metrics_MultinomialLogisticRegression_cv.csv\"\n",
    "        )\n",
    "        \n",
    "        print(i, method)\n",
    "        print(X_cf.shape, X_test.shape)\n",
    "    \n",
    "        ax = plot_all_cf(disc_model, flow, X_test, X_cf, metrics.iloc[i])\n",
    "        ax.set_title(method)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../models/BlobsDataset/{method}/visualization_{i}.png\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_image(folders, output_filename):\n",
    "    \"\"\"Creates a grid image combining images from multiple folders, with automatic grid calculation.\n",
    "\n",
    "    Args:\n",
    "        folders (list): A list of paths to folders containing images.\n",
    "        output_filename (str): Name of the output image file.\n",
    "    \"\"\"\n",
    "\n",
    "    images = []\n",
    "    for folder in folders:\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith((\".png\", \".jpg\")):\n",
    "                images.append(Image.open(os.path.join(folder, filename)))\n",
    "\n",
    "    # Calculate grid dimensions\n",
    "    num_images = len(images)\n",
    "    rows = math.ceil(math.sqrt(num_images))\n",
    "    cols = math.ceil(num_images / rows)\n",
    "\n",
    "    # Calculate image dimensions (assuming all have reasonably similar size)\n",
    "    image_width, image_height = images[0].size\n",
    "\n",
    "    grid_width = image_width * cols\n",
    "    grid_height = image_height * rows\n",
    "    grid_image = Image.new('RGB', (grid_width, grid_height))\n",
    "\n",
    "    index = 0\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            if index < num_images:  # Prevent going out of bounds\n",
    "                grid_image.paste(images[index], (col * image_width, row * image_height))\n",
    "            index += 1\n",
    "\n",
    "    grid_image.save(output_filename)\n",
    "\n",
    "\n",
    "folders = [f\"../models/BlobsDataset/{method}\" for method in ['artelth20', 'cbce', 'CEM', 'ppcef', 'wach']] # 'CEGP',\n",
    "output_filename = f\"../models/BlobsDataset/counterfactuals_logistic_regression_comparison.png\"\n",
    "\n",
    "create_grid_image(folders, output_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
