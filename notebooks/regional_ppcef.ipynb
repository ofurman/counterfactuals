{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from counterfactuals.datasets import MoonsDataset, LawDataset\n",
    "from counterfactuals.cf_methods.regional_ppcef import RPPCEF\n",
    "from counterfactuals.generative_models import MaskedAutoregressiveFlow\n",
    "from counterfactuals.discriminative_models import LogisticRegression\n",
    "from counterfactuals.losses import BinaryDiscLoss\n",
    "from counterfactuals.metrics.metrics import evaluate_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LawDataset(\"../data/law.csv\")\n",
    "train_dataloader = dataset.train_dataloader(batch_size=1024, shuffle=True)\n",
    "test_dataloader = dataset.test_dataloader(batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MoonsDataset(\"../data/moons.csv\")\n",
    "train_dataloader = dataset.train_dataloader(batch_size=1024, shuffle=True)\n",
    "test_dataloader = dataset.test_dataloader(batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_model = LogisticRegression(dataset.X_test.shape[1], 1)\n",
    "disc_model.load(\"../models/MoonsDataset/disc_model_LogisticRegression.pt\")\n",
    "# disc_model.fit(train_dataloader, test_dataloader, epochs=3000, lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((disc_model.predict(dataset.X_test).numpy() == dataset.y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = MaskedAutoregressiveFlow(\n",
    "    features=dataset.X_train.shape[1], hidden_features=4, context_features=1\n",
    ")\n",
    "dataset.y_train = disc_model.predict(dataset.X_train).detach().numpy()\n",
    "dataset.y_test = disc_model.predict(dataset.X_test).detach().numpy()\n",
    "gen_model.load(\"../models/MoonsDataset/gen_model_MaskedAutoregressiveFlow.pt\")\n",
    "# gen_train_dataloader = dataset.train_dataloader(batch_size=1024, shuffle=True, noise_lvl=0.03)\n",
    "# gen_model.fit(train_dataloader, test_dataloader, num_epochs=2000, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.X_test[dataset.y_test == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = RPPCEF(\n",
    "    K=dataset.X_test[dataset.y_test == 0].shape[0],\n",
    "    gen_model=gen_model,\n",
    "    disc_model=disc_model,\n",
    "    disc_model_criterion=BinaryDiscLoss(),\n",
    "    neptune_run=None,\n",
    ")\n",
    "# cf_dataloader = dataset.test_dataloader(batch_size=1024, shuffle=False)\n",
    "cf_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(dataset.X_test[dataset.y_test == 1]),\n",
    "        torch.from_numpy(dataset.y_test[dataset.y_test == 1]),\n",
    "    ),\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    ")\n",
    "median_log_prob = torch.median(gen_model.predict_log_prob(cf_dataloader))\n",
    "print(median_log_prob)\n",
    "deltas, X_orig, y_orig, y_target, logs = cf.search_batch(\n",
    "    cf_dataloader, alpha=100, median_log_prob=median_log_prob, epochs=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs[\"cf_search/loss_disc\"][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (log_name, log_vals) in enumerate(logs.items()):\n",
    "    plt.subplot(len(logs), 1, i + 1)\n",
    "    plt.plot(log_vals, label=log_name)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, S, D = deltas[0].get_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(S.sum(axis=0) != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_cfs = X_orig + deltas[0]().detach().numpy()\n",
    "\n",
    "model_returned = np.ones(Xs_cfs.shape[0]).astype(bool)\n",
    "\n",
    "\n",
    "metrics = evaluate_cf(\n",
    "    gen_model=gen_model,\n",
    "    disc_model=disc_model,\n",
    "    X_cf=Xs_cfs,\n",
    "    model_returned=model_returned,\n",
    "    categorical_features=dataset.categorical_features,\n",
    "    continuous_features=dataset.numerical_features,\n",
    "    X_train=dataset.X_train,\n",
    "    y_train=dataset.y_train.reshape(-1),\n",
    "    X_test=X_orig,\n",
    "    y_test=y_orig,\n",
    "    median_log_prob=median_log_prob,\n",
    "    S_matrix=S.detach().numpy(),\n",
    ")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cf = X_orig + deltas[0]().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "i = y_orig.reshape(-1) == 1\n",
    "ax.scatter(dataset.X_test[:, 0], dataset.X_test[:, 1], c=dataset.y_test, alpha=0.5)\n",
    "ax.scatter(X_cf[i, 0], X_cf[i, 1], c=\"r\")\n",
    "for before, after in zip(X_orig[i], X_cf[i]):\n",
    "    ax.arrow(\n",
    "        before[0],\n",
    "        before[1],\n",
    "        after[0] - before[0],\n",
    "        after[1] - before[1],\n",
    "        head_width=0.0,\n",
    "        head_length=0.0,\n",
    "        fc=\"gray\",\n",
    "        ec=\"gray\",\n",
    "        alpha=0.5,\n",
    "        width=0.0001,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(10, 2)\n",
    "torch.linalg.vector_norm(torch.rand(10, 2), dim=1, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    \"parameters/dataset\": \"Dataset\",\n",
    "    \"metrics/cf/K_vectors\": \"K\",\n",
    "    \"metrics/cf/valid_cf_disc\": \"Validity\",\n",
    "    \"metrics/cf/flow_prob_condition_acc\": \"Prob. Plaus\",\n",
    "    \"metrics/cf/cf_belongs_to_group\": \"CFs assigned to Group\",\n",
    "    \"metrics/cf/flow_log_density_cfs\": \"Log Dens.\",\n",
    "    \"metrics/cf/dissimilarity_proximity_continuous_euclidean\": \"L2\",\n",
    "    \"metrics/cf/dissimilarity_proximity_continuous_manhatan\": \"L1\",\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
