{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ofurman/Study/counterfactuals/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from nflows.flows import MaskedAutoregressiveFlow\n",
    "\n",
    "from counterfactuals.datasets import (\n",
    "    AdultDataset,\n",
    "    GermanCreditDataset,\n",
    "    CompasDataset,\n",
    "    HelocDataset,\n",
    "    LawDataset,\n",
    "    MoonsDataset,\n",
    ")\n",
    "\n",
    "from counterfactuals.optimizers.base import BaseCounterfactualModel\n",
    "from counterfactuals.optimizers.approach_three import ApproachThree\n",
    "\n",
    "from counterfactuals.metrics.metrics import (\n",
    "    perc_valid_cf,\n",
    "    perc_valid_actionable_cf,\n",
    "    continuous_distance,\n",
    "    categorical_distance,\n",
    "    distance_l2_jaccard,\n",
    "    distance_mad_hamming,\n",
    "    plausibility,\n",
    "    evaluate_cf,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CompasDataset(file_path=\"../data/compas_two_years.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.85      0.82       281\n",
      "         1.0       0.84      0.78      0.81       281\n",
      "\n",
      "    accuracy                           0.82       562\n",
      "   macro avg       0.82      0.82      0.82       562\n",
      "weighted avg       0.82      0.82      0.82       562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# disc_model = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=100)\n",
    "disc_model = LogisticRegression()\n",
    "disc_model.fit(dataset.X_train, dataset.y_train.reshape(-1))\n",
    "print(classification_report(dataset.y_test, disc_model.predict(dataset.X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relabeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = disc_model.predict(dataset.X_train)\n",
    "y_pred_test = disc_model.predict(dataset.X_test)\n",
    "dataset.y_train = y_pred_train\n",
    "dataset.y_test = y_pred_test\n",
    "\n",
    "# noise_lvl - zaszumianie numerycznych cech treningowego datasetu\n",
    "train_dataloader = dataset.train_dataloader(batch_size=128, shuffle=True, noise_lvl=0)\n",
    "test_dataloader = dataset.test_dataloader(batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create flow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = MaskedAutoregressiveFlow(features=dataset.X_train.shape[1], hidden_features=4, num_blocks_per_layer=2, num_layers=1, context_features=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define custom search step within class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomApproach(BaseCounterfactualModel):\n",
    "    def search_step(self, x_param, x_origin, context_origin, context_target, **search_step_kwargs):\n",
    "        alpha = search_step_kwargs.get(\"alpha\", None)\n",
    "        beta = search_step_kwargs.get(\"beta\", None)\n",
    "        if alpha is None:\n",
    "            raise ValueError(\"Parameter 'alpha' should be in kwargs\")\n",
    "        if beta is None:\n",
    "            raise ValueError(\"Parameter 'beta' should be in kwargs\")\n",
    "\n",
    "        dist = torch.linalg.norm(x_origin-x_param, axis=1)\n",
    "\n",
    "        p_x_param_c_orig = self.model.log_prob(x_param, context=context_origin)\n",
    "        p_x_param_c_target = self.model.log_prob(x_param, context=context_target)\n",
    "        p_x_orig_c_orig = self.model.log_prob(x_origin, context=context_origin.flatten()[0].repeat((x_origin.shape[0], 1)))\n",
    "\n",
    "        p_x_param_c_orig_with_beta = p_x_param_c_orig + beta\n",
    "        max_inner = torch.nn.functional.relu(p_x_orig_c_orig-p_x_param_c_target)\n",
    "        max_outer = torch.nn.functional.relu(p_x_param_c_orig_with_beta - p_x_param_c_target)\n",
    "        loss = dist + alpha * (max_outer + max_inner)\n",
    "        return loss, dist, max_inner, max_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cf class, train and test flow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = CustomApproach(model=flow, checkpoint_path=\"model.pt\", neptune_run=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ofurman/Study/counterfactuals/venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/ofurman/Study/counterfactuals/venv/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Epoch 9999, Train: -1.5071, test: -3.2061: 100%|██████████| 10000/10000 [04:47<00:00, 34.77it/s]\n"
     ]
    }
   ],
   "source": [
    "cf.train_model(\n",
    "    train_loader=train_dataloader,\n",
    "    test_loader=test_dataloader,\n",
    "    epochs=10000,\n",
    "    lr=0.001,\n",
    "    patience=20,\n",
    "    eps=1e-3, # eps for patience\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.0': {'precision': 0.8904109589041096,\n",
       "  'recall': 0.8609271523178808,\n",
       "  'f1-score': 0.8754208754208754,\n",
       "  'support': 302.0},\n",
       " '1.0': {'precision': 0.8444444444444444,\n",
       "  'recall': 0.8769230769230769,\n",
       "  'f1-score': 0.860377358490566,\n",
       "  'support': 260.0},\n",
       " 'accuracy': 0.8683274021352313,\n",
       " 'macro avg': {'precision': 0.8674277016742771,\n",
       "  'recall': 0.8689251146204788,\n",
       "  'f1-score': 0.8678991169557206,\n",
       "  'support': 562.0},\n",
       " 'weighted avg': {'precision': 0.8691453116451897,\n",
       "  'recall': 0.8683274021352313,\n",
       "  'f1-score': 0.8684612412538284,\n",
       "  'support': 562.0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.test_model(test_loader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:19<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "search_step_kwargs = {\n",
    "    \"alpha\": 20,\n",
    "    \"beta\": 0.1,\n",
    "}\n",
    "test_dataloader = dataset.test_dataloader(batch_size=16, shuffle=False)\n",
    "Xs_cf, Xs_orig, ys_orig = cf.search_batch(\n",
    "    dataloader=test_dataloader,\n",
    "    epochs=500,\n",
    "    lr=0.001,\n",
    "    **search_step_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_returned_smth': 1.0,\n",
       " 'valid_cf_disc': 0.5195729537366548,\n",
       " 'dissimilarity_proximity_categorical_hamming': 0.9820205479452054,\n",
       " 'dissimilarity_proximity_categorical_jaccard': 0.9820205479452054,\n",
       " 'dissimilarity_proximity_continuous_manhatan': 1.01149155518431,\n",
       " 'dissimilarity_proximity_continuous_euclidean': 0.47161848841062187,\n",
       " 'dissimilarity_proximity_continuous_mad': 44.128832385833576,\n",
       " 'distance_l2_jaccard': 0.7438329201623998,\n",
       " 'distance_mad_hamming': 21.117199405626444,\n",
       " 'plausibility': 21.014522688081886,\n",
       " 'kde_log_density': -0.5961783704183525,\n",
       " 'sparsity': 0.9904109589041096}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_cf(\n",
    "    disc_model=disc_model,\n",
    "    X=Xs_orig,\n",
    "    X_cf=Xs_cf,\n",
    "    model_returned=np.ones(Xs_cf.shape[0]).astype(bool),\n",
    "    continuous_features=dataset.numerical_features,\n",
    "    categorical_features=dataset.categorical_features,\n",
    "    X_train=dataset.X_train,\n",
    "    y_train=dataset.y_train,\n",
    "    X_test=dataset.X_test,\n",
    "    y_test=dataset.y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
