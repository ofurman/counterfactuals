{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from counterfactuals.datasets import PolishBankDataset, WineDataset\n",
    "from counterfactuals.discriminative_models import MultilayerPerceptron\n",
    "\n",
    "# from counterfactuals.losses import MulticlassDiscLoss\n",
    "from counterfactuals.generative_models import MaskedAutoregressiveFlow\n",
    "from counterfactuals.cf_methods.ppcef import PPCEF\n",
    "from counterfactuals.metrics.metrics import evaluate_cf\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = BlobsDataset(\"../data/blobs.csv\")\n",
    "dataset = PolishBankDataset(\"../data/polish_bankruptcy.csv\")\n",
    "# dataset = MoonsDataset(\"../data/moons.csv\")\n",
    "dataset = WineDataset(\"../data/wine.csv\")\n",
    "train_dataloader = dataset.train_dataloader(\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    noise_lvl=0,\n",
    ")\n",
    "test_dataloader = dataset.test_dataloader(batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_model = MultilayerPerceptron(\n",
    "    input_size=dataset.X_test.shape[1], target_size=3, hidden_layer_sizes=[256, 128]\n",
    ")\n",
    "disc_model.fit(\n",
    "    dataset.train_dataloader(128, True),\n",
    "    dataset.test_dataloader(128, False),\n",
    "    epochs=500,\n",
    "    lr=1e-5,\n",
    ")\n",
    "preds = disc_model.predict(dataset.X_test)\n",
    "print(classification_report(dataset.y_test.flatten(), preds.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = MaskedAutoregressiveFlow(\n",
    "    features=dataset.X_test.shape[1],\n",
    "    hidden_features=8,\n",
    "    num_layers=2,\n",
    "    context_features=1,\n",
    "    device=device,\n",
    ")\n",
    "gen_model.fit(train_dataloader, test_dataloader, num_epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 5)\n",
    "\n",
    "xline = torch.linspace(-0.5, 1.5, 200)\n",
    "yline = torch.linspace(-0.5, 1.5, 200)\n",
    "xgrid, ygrid = torch.meshgrid(xline, yline)\n",
    "xyinput = torch.cat([xgrid.reshape(-1, 1), ygrid.reshape(-1, 1)], dim=1)\n",
    "\n",
    "context_zero = torch.full((xyinput.shape[0], 1), 0, dtype=torch.float32)\n",
    "context_one = torch.full((xyinput.shape[0], 1), 1, dtype=torch.float32)\n",
    "context_two = torch.full((xyinput.shape[0], 1), 2, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    zgrid = gen_model(xyinput, context_one)\n",
    "    zgrid = zgrid.reshape(200, 200).exp().numpy()\n",
    "\n",
    "cs = ax.contourf(xgrid.numpy(), ygrid.numpy(), zgrid, levels=100, cmap=cm.PuBu_r)\n",
    "cbar = fig.colorbar(cs)  # noqa: F841"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "with torch.no_grad():\n",
    "    for x, y in zip(dataset.X_test, dataset.y_test):\n",
    "        x = torch.from_numpy(x).view(1, -1)\n",
    "        y_zero = torch.Tensor([0])\n",
    "        y_one = torch.Tensor([1])\n",
    "        y_two = torch.Tensor([2])\n",
    "        y_pred = np.argmax(\n",
    "            [\n",
    "                gen_model(x, y_zero).item(),\n",
    "                gen_model(x, y_one).item(),\n",
    "                gen_model(x, y_two).item(),\n",
    "            ]\n",
    "        )\n",
    "        y_preds.append(y_pred)\n",
    "print(classification_report(dataset.y_test.flatten(), y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MulticlassDiscLoss(torch.nn.modules.loss._Loss):\n",
    "#     def __init__(\n",
    "#         self, size_average=None, reduce=None, reduction: str = \"mean\", eps=0.02\n",
    "#     ) -> None:\n",
    "#         super().__init__(size_average, reduce, reduction)\n",
    "#         self.eps = eps\n",
    "\n",
    "#     def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "#         return torch.nn.functional.cross_entropy(input, target.view(-1))\n",
    "\n",
    "\n",
    "class MulticlassDiscLoss(torch.nn.modules.loss._Loss):\n",
    "    def __init__(\n",
    "        self, size_average=None, reduce=None, reduction: str = \"mean\", eps=0.02\n",
    "    ) -> None:\n",
    "        super().__init__(size_average, reduce, reduction)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        one_hot = torch.eye(3)[target][:, 0, :]\n",
    "        dot_product = torch.sum(input * one_hot, dim=1)\n",
    "        return torch.norm(dot_product - torch.max(input, dim=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = MulticlassDiscLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = PPCEF(\n",
    "    gen_model=gen_model,\n",
    "    disc_model=disc_model,\n",
    "    disc_model_criterion=loss_fn,\n",
    "    neptune_run=None,\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = torch.median(gen_model.predict_log_prob(train_dataloader))\n",
    "cf_dataloader = dataset.test_dataloader(batch_size=1024, shuffle=False)\n",
    "Xs_cfs, Xs, ys_orig, ys_target, loss_components = cf.search_batch(\n",
    "    cf_dataloader,\n",
    "    epochs=5000,\n",
    "    patience=200,\n",
    "    lr=0.005,\n",
    "    alpha=100,\n",
    "    delta=delta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_components.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, v) in enumerate(loss_components.items(), 1):\n",
    "    plt.subplot(4, 1, i)\n",
    "    plt.plot(v, label=k)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_cf(\n",
    "    gen_model=gen_model,\n",
    "    disc_model=disc_model,\n",
    "    y_target=ys_target,\n",
    "    X_cf=Xs_cfs,\n",
    "    model_returned=np.ones(Xs_cfs.shape[0], dtype=bool),\n",
    "    categorical_features=dataset.categorical_features,\n",
    "    continuous_features=dataset.numerical_features,\n",
    "    X_train=dataset.X_train,\n",
    "    y_train=dataset.y_train.reshape(-1),\n",
    "    X_test=dataset.X_test,\n",
    "    y_test=dataset.y_test,\n",
    "    delta=delta.numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
