{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=2**10, noise=0.1, random_state=42)\n",
    "data = pd.DataFrame(np.hstack([X, y.reshape(-1, 1)]))\n",
    "data.to_csv(\"../data/moons.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "heloc_df = pd.read_csv(\"../data/heloc.csv\")\n",
    "heloc_df[\"RiskPerformance\"] = heloc_df[\"RiskPerformance\"].map({\"Bad\": 0, \"Good\": 1})\n",
    "\n",
    "# Prepare the data for modeling\n",
    "X = heloc_df.drop(\"RiskPerformance\", axis=1)\n",
    "y = heloc_df[\"RiskPerformance\"]\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the testing data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.DataFrame(\n",
    "    rf_model.feature_importances_, index=X.columns, columns=[\"importance\"]\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/adult.csv\")\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df[df[\"income\"] == 0].sample(df[\"income\"].sum(), random_state=42),\n",
    "        df[df[\"income\"] == 1],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_law = pd.read_csv(\"../data/law.csv\")\n",
    "columns = [\"lsat\", \"gpa\", \"zfygpa\", \"pass_bar\", \"sex\", \"race\"]\n",
    "df_law = df_law[columns]\n",
    "df_law.dropna().corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/compas_two_years.csv\", index_col=\"id\")\n",
    "columns = [\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"race\",\n",
    "    \"priors_count\",\n",
    "    \"days_b_screening_arrest\",\n",
    "    \"c_jail_in\",\n",
    "    \"c_jail_out\",\n",
    "    \"c_charge_degree\",\n",
    "    \"is_recid\",\n",
    "    \"is_violent_recid\",\n",
    "    \"two_year_recid\",\n",
    "    \"decile_score\",\n",
    "    \"score_text\",\n",
    "]\n",
    "df = df[columns]\n",
    "df[\"days_b_screening_arrest\"] = np.abs(df[\"days_b_screening_arrest\"])\n",
    "df[\"c_jail_out\"] = pd.to_datetime(df[\"c_jail_out\"])\n",
    "df[\"c_jail_in\"] = pd.to_datetime(df[\"c_jail_in\"])\n",
    "df[\"length_of_stay\"] = np.abs((df[\"c_jail_out\"] - df[\"c_jail_in\"]).dt.days)\n",
    "df[\"length_of_stay\"].fillna(df[\"length_of_stay\"].value_counts().index[0], inplace=True)\n",
    "df[\"days_b_screening_arrest\"].fillna(\n",
    "    df[\"days_b_screening_arrest\"].value_counts().index[0], inplace=True\n",
    ")\n",
    "df[\"length_of_stay\"] = df[\"length_of_stay\"].astype(int)\n",
    "df[\"days_b_screening_arrest\"] = df[\"days_b_screening_arrest\"].astype(int)\n",
    "df = df[df[\"score_text\"] != \"Medium\"]\n",
    "df[\"class\"] = pd.get_dummies(df[\"score_text\"])[\"High\"].astype(int)\n",
    "df.drop([\"c_jail_in\", \"c_jail_out\", \"decile_score\", \"score_text\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(n_class=2, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the MNIST dataset\n",
    "X, y = load_digits(n_class=2, return_X_y=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
    ")\n",
    "\n",
    "# Apply PCA to reduce the dimensionality of the data\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polish bankruptcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def convert_arff_to_csv(arff_path):\n",
    "    # Using pandas to read the ARFF file\n",
    "    # skiprows is used to skip the file's header information\n",
    "    data = pd.read_csv(arff_path, comment=\"@\", header=None)\n",
    "\n",
    "    # Extracting the attribute names from the file\n",
    "    attribute_names = []\n",
    "    with open(arff_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"@attribute\"):\n",
    "                attribute_name = line.split(\" \")[1].strip()\n",
    "                attribute_names.append(attribute_name)\n",
    "\n",
    "    # Assigning the attribute names to the dataframe columns\n",
    "    data.columns = attribute_names\n",
    "\n",
    "    # Saving to a CSV file\n",
    "    # csv_path = arff_path.replace(\".arff\", \".csv\")\n",
    "    # data.to_csv(csv_path, index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# csv_file_path = convert_arff_to_csv(file_path)\n",
    "# csv_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine-quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_red = pd.read_csv(\"../data/regression/winequality-red.csv\", sep=\";\")\n",
    "df_white = pd.read_csv(\"../data/regression/winequality-white.csv\", sep=\";\")\n",
    "df = pd.concat([df_red, df_white])\n",
    "df.to_csv(\"../data/regression/winequality.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
