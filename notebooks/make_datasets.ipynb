{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=2**10, noise=0.1, random_state=42)\n",
    "data = pd.DataFrame(np.hstack([X, y.reshape(-1 ,1)]))\n",
    "data.to_csv(\"../data/moons.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "heloc_df = pd.read_csv(\"../data/heloc.csv\")\n",
    "heloc_df['RiskPerformance'] = heloc_df['RiskPerformance'].map({'Bad': 0, 'Good': 1})\n",
    "\n",
    "# Prepare the data for modeling\n",
    "X = heloc_df.drop('RiskPerformance', axis=1)\n",
    "y = heloc_df['RiskPerformance']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the testing data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.DataFrame(rf_model.feature_importances_, index = X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "min_features_to_select = 3  # Minimum number of features to consider\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "cv = StratifiedKFold(5)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=clf,\n",
    "    step=1,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    min_features_to_select=min_features_to_select,\n",
    "    n_jobs=2,\n",
    ")\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_scores = len(rfecv.cv_results_[\"mean_test_score\"])\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Mean test accuracy\")\n",
    "plt.errorbar(\n",
    "    range(min_features_to_select, n_scores + min_features_to_select),\n",
    "    rfecv.cv_results_[\"mean_test_score\"],\n",
    "    yerr=rfecv.cv_results_[\"std_test_score\"],\n",
    ")\n",
    "plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "plt.show()\n",
    "\n",
    "selected_features_rfecv = X.columns[rfecv.support_]\n",
    "print(selected_features_rfecv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/heloc.csv\")\n",
    "df['RiskPerformance'] = df['RiskPerformance'].map({'Bad': 0, 'Good': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'RiskPerformance'\n",
    "feature_columns = df.columns.drop(target_column)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/adult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    df[df[\"income\"] == 0].sample(df[\"income\"].sum(), random_state=42),\n",
    "    df[df[\"income\"] == 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"workclass\"].value_counts()\n",
    "# df[\"education\"].value_counts()\n",
    "# df[\"marital_status\"].value_counts()\n",
    "# df[\"occupation\"].value_counts()\n",
    "df[\"gender\"].value_counts()\n",
    "df[\"race\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_law = pd.read_csv(\"../data/law.csv\")\n",
    "columns = [\"lsat\", \"gpa\", \"zfygpa\",\"pass_bar\", \"sex\", \"race\"]\n",
    "df_law = df_law[columns]\n",
    "df_law.dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_law[\"race\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_law[\"pass_bar\"] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/compas_two_years.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'sex', 'race', 'priors_count', 'days_b_screening_arrest', 'c_jail_in', 'c_jail_out',\n",
    "               'c_charge_degree', 'is_recid', 'is_violent_recid', 'two_year_recid', 'decile_score', 'score_text']\n",
    "df = df[columns]\n",
    "df['days_b_screening_arrest'] = np.abs(df['days_b_screening_arrest'])\n",
    "df['c_jail_out'] = pd.to_datetime(df['c_jail_out'])\n",
    "df['c_jail_in'] = pd.to_datetime(df['c_jail_in'])\n",
    "df['length_of_stay'] = np.abs((df['c_jail_out'] - df['c_jail_in']).dt.days)\n",
    "df['length_of_stay'].fillna(df['length_of_stay'].value_counts().index[0], inplace=True)\n",
    "df['days_b_screening_arrest'].fillna(df['days_b_screening_arrest'].value_counts().index[0], inplace=True)\n",
    "df['length_of_stay'] = df['length_of_stay'].astype(int)\n",
    "df['days_b_screening_arrest'] = df['days_b_screening_arrest'].astype(int)\n",
    "df = df[df[\"score_text\"] != \"Medium\"]\n",
    "df[\"class\"] = pd.get_dummies(df[\"score_text\"])[\"High\"].astype(int)\n",
    "df.drop(['c_jail_in', 'c_jail_out', 'decile_score', 'score_text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/german_credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"default\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(n_class=2, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the MNIST dataset\n",
    "X, y = load_digits(n_class=2, return_X_y=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "# Apply PCA to reduce the dimensionality of the data\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polish bankruptcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def convert_arff_to_csv(arff_path):\n",
    "    # Using pandas to read the ARFF file\n",
    "    # skiprows is used to skip the file's header information\n",
    "    data = pd.read_csv(arff_path, comment='@', header=None)\n",
    "    \n",
    "    # Extracting the attribute names from the file\n",
    "    attribute_names = []\n",
    "    with open(arff_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('@attribute'):\n",
    "                attribute_name = line.split(' ')[1].strip()\n",
    "                attribute_names.append(attribute_name)\n",
    "\n",
    "    # Assigning the attribute names to the dataframe columns\n",
    "    data.columns = attribute_names\n",
    "\n",
    "    # Saving to a CSV file\n",
    "    csv_path = arff_path.replace('.arff', '.csv')\n",
    "    # data.to_csv(csv_path, index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "# csv_file_path = convert_arff_to_csv(file_path)\n",
    "# csv_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.read_csv(\"../data/polish_bankruptcy.csv\")\n",
    "# map values in the df from '?' to np.nan\n",
    "df = df.replace('?', np.nan)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.isnull().mean() < 0.01].dropna()\n",
    "import numpy as np\n",
    "\n",
    "# corr_matrix = df.corr().abs()\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "# df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    df[df[\"class\"] == 0].sample(df[\"class\"].sum(), random_state=42),\n",
    "    df[df[\"class\"] == 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arff_paths = [f\"../data/{p}\" for p in os.listdir(\"../data\") if p.endswith(\".csv\")]\n",
    "\n",
    "dfs = []\n",
    "for arff_path in arff_paths:\n",
    "    df = convert_arff_to_csv(arff_path)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv(\"../data/polish_bankruptcy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/audit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Risk\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Audit_Risk\"].corr(df[\"Risk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
