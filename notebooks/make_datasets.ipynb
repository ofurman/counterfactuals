{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=2**10, noise=0.1, random_state=42)\n",
    "data = pd.DataFrame(np.hstack([X, y.reshape(-1, 1)]))\n",
    "data.to_csv(\"../data/moons.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "heloc_df = pd.read_csv(\"../data/heloc.csv\")\n",
    "heloc_df[\"RiskPerformance\"] = heloc_df[\"RiskPerformance\"].map({\"Bad\": 0, \"Good\": 1})\n",
    "\n",
    "# Prepare the data for modeling\n",
    "X = heloc_df.drop(\"RiskPerformance\", axis=1)\n",
    "y = heloc_df[\"RiskPerformance\"]\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the testing data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.DataFrame(\n",
    "    rf_model.feature_importances_, index=X.columns, columns=[\"importance\"]\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/adult.csv\")\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df[df[\"income\"] == 0].sample(df[\"income\"].sum(), random_state=42),\n",
    "        df[df[\"income\"] == 1],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_law = pd.read_csv(\"../data/law.csv\")\n",
    "columns = [\"lsat\", \"gpa\", \"zfygpa\", \"pass_bar\", \"sex\", \"race\"]\n",
    "df_law = df_law[columns]\n",
    "df_law.dropna().corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/compas_two_years.csv\", index_col=\"id\")\n",
    "columns = [\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"race\",\n",
    "    \"priors_count\",\n",
    "    \"days_b_screening_arrest\",\n",
    "    \"c_jail_in\",\n",
    "    \"c_jail_out\",\n",
    "    \"c_charge_degree\",\n",
    "    \"is_recid\",\n",
    "    \"is_violent_recid\",\n",
    "    \"two_year_recid\",\n",
    "    \"decile_score\",\n",
    "    \"score_text\",\n",
    "]\n",
    "df = df[columns]\n",
    "df[\"days_b_screening_arrest\"] = np.abs(df[\"days_b_screening_arrest\"])\n",
    "df[\"c_jail_out\"] = pd.to_datetime(df[\"c_jail_out\"])\n",
    "df[\"c_jail_in\"] = pd.to_datetime(df[\"c_jail_in\"])\n",
    "df[\"length_of_stay\"] = np.abs((df[\"c_jail_out\"] - df[\"c_jail_in\"]).dt.days)\n",
    "df[\"length_of_stay\"].fillna(df[\"length_of_stay\"].value_counts().index[0], inplace=True)\n",
    "df[\"days_b_screening_arrest\"].fillna(\n",
    "    df[\"days_b_screening_arrest\"].value_counts().index[0], inplace=True\n",
    ")\n",
    "df[\"length_of_stay\"] = df[\"length_of_stay\"].astype(int)\n",
    "df[\"days_b_screening_arrest\"] = df[\"days_b_screening_arrest\"].astype(int)\n",
    "df = df[df[\"score_text\"] != \"Medium\"]\n",
    "df[\"class\"] = pd.get_dummies(df[\"score_text\"])[\"High\"].astype(int)\n",
    "df.drop([\"c_jail_in\", \"c_jail_out\", \"decile_score\", \"score_text\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(n_class=2, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the MNIST dataset\n",
    "X, y = load_digits(n_class=2, return_X_y=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
    ")\n",
    "\n",
    "# Apply PCA to reduce the dimensionality of the data\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polish bankruptcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def convert_arff_to_csv(arff_path):\n",
    "    # Using pandas to read the ARFF file\n",
    "    # skiprows is used to skip the file's header information\n",
    "    data = pd.read_csv(arff_path, comment=\"@\", header=None)\n",
    "\n",
    "    # Extracting the attribute names from the file\n",
    "    attribute_names = []\n",
    "    with open(arff_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"@attribute\"):\n",
    "                attribute_name = line.split(\" \")[1].strip()\n",
    "                attribute_names.append(attribute_name)\n",
    "\n",
    "    # Assigning the attribute names to the dataframe columns\n",
    "    data.columns = attribute_names\n",
    "\n",
    "    # Saving to a CSV file\n",
    "    # csv_path = arff_path.replace(\".arff\", \".csv\")\n",
    "    # data.to_csv(csv_path, index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# csv_file_path = convert_arff_to_csv(file_path)\n",
    "# csv_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine-quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/regression/winequality-red.csv\")\n",
    "# df_white = pd.read_csv(\"../data/regression/winequality-white.csv\", sep=\";\")\n",
    "# df = pd.concat([df_red, df_white])\n",
    "# df.to_csv(\"../data/regression/winequality-red.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yacht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/regression/yacht/data.txt\", sep=\" \", header=None)\n",
    "df.to_csv(\"../data/regression/yacht.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/regression/concrete/data.txt\", sep=\" \", header=None)\n",
    "df.to_csv(\"../data/regression/concrete.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3     4       5      6    7      8\n",
       "0     540.0    0.0    0.0  162.0   2.5  1040.0  676.0   28  79.99\n",
       "1     540.0    0.0    0.0  162.0   2.5  1055.0  676.0   28  61.89\n",
       "2     332.5  142.5    0.0  228.0   0.0   932.0  594.0  270  40.27\n",
       "3     332.5  142.5    0.0  228.0   0.0   932.0  594.0  365  41.05\n",
       "4     198.6  132.4    0.0  192.0   0.0   978.4  825.5  360  44.30\n",
       "...     ...    ...    ...    ...   ...     ...    ...  ...    ...\n",
       "1025  276.4  116.0   90.3  179.6   8.9   870.1  768.3   28  44.28\n",
       "1026  322.2    0.0  115.6  196.0  10.4   817.9  813.4   28  31.18\n",
       "1027  148.5  139.4  108.6  192.7   6.1   892.4  780.0   28  23.70\n",
       "1028  159.1  186.7    0.0  175.6  11.3   989.6  788.9   28  32.77\n",
       "1029  260.9  100.5   78.3  200.6   8.6   864.5  761.5   28  32.40\n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import pandas as pd\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "df = pd.DataFrame(X)\n",
    "df[10] = y\n",
    "# df.to_csv(\"../data/regression/diabetes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scm20d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8966, 61)\n",
      "(8966, 16)\n"
     ]
    }
   ],
   "source": [
    "df_x = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(\"../data/regression/scm20d/x_train.csv\", header=None),\n",
    "        pd.read_csv(\"../data/regression/scm20d/x_test.csv\", header=None),\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "print(df_x.shape)\n",
    "\n",
    "df_y = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(\"../data/regression/scm20d/y_train.csv\", header=None),\n",
    "        pd.read_csv(\"../data/regression/scm20d/y_test.csv\", header=None),\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "print(df_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_x, df_y], axis=1)\n",
    "df.to_csv(\"../data/regression/scm20d.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "\n",
    "X_large, y_large = make_regression(\n",
    "    n_samples=1000, n_features=2, noise=0.1, random_state=32\n",
    ")\n",
    "df = pd.DataFrame(X_large)\n",
    "df[2] = y_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/regression/toy_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
