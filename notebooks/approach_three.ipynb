{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.flows import MaskedAutoregressiveFlow\n",
    "\n",
    "from counterfactuals.datasets.heloc import HelocDataset\n",
    "from counterfactuals.datasets.moons import MoonsDataset\n",
    "from counterfactuals.datasets.law import LawDataset\n",
    "\n",
    "from counterfactuals.optimizers.approach_three import ApproachThree\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MoonsDataset(file_path=\"../data/origin/moons.csv\")\n",
    "train_dataloader = dataset.train_dataloader(batch_size=64, shuffle=True)\n",
    "test_dataloader = dataset.test_dataloader(batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = MaskedAutoregressiveFlow(features=2, hidden_features=4, context_features=1)\n",
    "cf = ApproachThree(model=flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   1%|          | 1/100 [00:00<01:28,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train: 2.596069495399277, test: 1.5107005421931927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  11%|█         | 11/100 [00:09<01:16,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train: 0.4136806981904166, test: 0.3962578194645735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  21%|██        | 21/100 [00:18<01:09,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train: 0.38746631203533766, test: 0.3670947884137814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  31%|███       | 31/100 [00:27<01:01,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train: 0.38016107975146474, test: 0.3412010302910438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  41%|████      | 41/100 [00:35<00:52,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train: 0.37500727931400396, test: 0.35000217304779935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  51%|█████     | 51/100 [00:44<00:42,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train: 0.37014528699380495, test: 0.3890980057991468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  61%|██████    | 61/100 [00:53<00:33,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Train: 0.3693278684760585, test: 0.3419209982340152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  71%|███████   | 71/100 [01:01<00:24,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Train: 0.3694960878782974, test: 0.37113581081995595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  81%|████████  | 81/100 [01:10<00:16,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Train: 0.36569751095978215, test: 0.34506069811490864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  91%|█████████ | 91/100 [01:19<00:07,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Train: 0.36315509496313153, test: 0.36652979942468494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 100/100 [01:27<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "cf.train_model(\n",
    "    train_loader=train_dataloader,\n",
    "    test_loader=test_dataloader,\n",
    "    epochs=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_train_dataloader = DataLoader(\n",
    "#     dataset=TensorDataset(torch.from_numpy(dataset.X_train), torch.from_numpy(y_pred_train)),\n",
    "#     batch_size=64\n",
    "# )\n",
    "\n",
    "# pred_test_dataloader = DataLoader(\n",
    "#     dataset=TensorDataset(torch.from_numpy(dataset.X_test), torch.from_numpy(y_pred_test)),\n",
    "#     batch_size=64\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clf = LogisticRegression()\n",
    "# clf = MLPClassifier((128, 64), max_iter=100)\n",
    "# clf.fit(dataset.X_train, dataset.y_train)\n",
    "# y_pred_train = clf.predict(dataset.X_train)\n",
    "# y_pred_test = clf.predict(dataset.X_test)\n",
    "# print(classification_report(dataset.y_test, y_pred_test, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       797\n",
      "         1.0       1.00      1.00      1.00       842\n",
      "\n",
      "    accuracy                           1.00      1639\n",
      "   macro avg       1.00      1.00      1.00      1639\n",
      "weighted avg       1.00      1.00      1.00      1639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf.test_model(test_loader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:01,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "Xs_cfs = cf.generate_counterfactuals(Xs=dataset.X_test[:100], ys=dataset.y_test[:100], num_epochs=100, lr=0.005, alpha=20, beta=0.01)\n",
    "Xs_cfs = torch.concat(Xs_cfs).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cfs_pred = clf.predict(Xs_cfs)\n",
    "y_clf_pred = clf.predict(dataset.X_test[:100])\n",
    "\n",
    "np.sum(y_cfs_pred != y_clf_pred) / y_clf_pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CF Metrics for Flow predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_cfs_pred = cf.predict_model(Xs_cfs)\n",
    "ys_orig_pred = cf.predict_model(dataset.X_test[:100])\n",
    "\n",
    "np.sum(ys_cfs_pred != ys_orig_pred) / ys_orig_pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CF Metrics for real test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_cfs_pred = cf.predict_model(Xs_cfs)\n",
    "ys_orig_pred = dataset.y_test[:100].flatten()\n",
    "\n",
    "np.sum(ys_cfs_pred != ys_orig_pred) / ys_orig_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ofurman/Study/counterfactuals/venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ofurman/Study/counterfactuals/venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "dataset = HelocDataset(file_path=\"../data/origin/heloc.csv\")\n",
    "train_dataloader = dataset.train_dataloader(batch_size=64, shuffle=True)\n",
    "test_dataloader = dataset.test_dataloader(batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   1%|          | 1/100 [00:00<00:47,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train: 36.58724835132425, test: -4.480853648746715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  11%|█         | 11/100 [00:05<00:41,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train: -24.826751154822272, test: -24.831530739279355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  21%|██        | 21/100 [00:09<00:36,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train: -27.429956590807116, test: -27.49938908745261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  31%|███       | 31/100 [00:14<00:32,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train: -28.884426220043284, test: -29.027672599343692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  41%|████      | 41/100 [00:19<00:29,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train: -29.904790775195973, test: -29.81248238507439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  51%|█████     | 51/100 [00:24<00:24,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train: -30.66202299014942, test: -30.59963091681985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  61%|██████    | 61/100 [00:29<00:18,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Train: -31.252052165366507, test: -30.633462457095874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  71%|███████   | 71/100 [00:33<00:13,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Train: -32.13748083887874, test: -32.01008044972139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  81%|████████  | 81/100 [00:38<00:09,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Train: -32.83665147987572, test: -32.60954150031595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  91%|█████████ | 91/100 [00:43<00:04,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Train: -33.23829447256552, test: -31.960235371309167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 100/100 [00:47<00:00,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "flow = MaskedAutoregressiveFlow(features=23, hidden_features=4, context_features=1)\n",
    "cf = ApproachThree(model=flow)\n",
    "cf.train_model(\n",
    "    train_loader=train_dataloader,\n",
    "    test_loader=test_dataloader,\n",
    "    epochs=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.49      0.57       556\n",
      "         1.0       0.57      0.76      0.65       490\n",
      "\n",
      "    accuracy                           0.62      1046\n",
      "   macro avg       0.63      0.62      0.61      1046\n",
      "weighted avg       0.64      0.62      0.61      1046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf.test_model(test_loader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:46,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "Xs_cfs = cf.generate_counterfactuals(Xs=dataset.X_test[:100], ys=dataset.y_test[:100], num_epochs=100, lr=0.005, alpha=20, beta=0.01)\n",
    "Xs_cfs = torch.concat(Xs_cfs).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.76      0.75       556\n",
      "         1.0       0.72      0.69      0.70       490\n",
      "\n",
      "    accuracy                           0.73      1046\n",
      "   macro avg       0.72      0.72      0.72      1046\n",
      "weighted avg       0.73      0.73      0.73      1046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logr = LogisticRegression()\n",
    "logr.fit(dataset.X_train, dataset.y_train)\n",
    "y_pred_logr = logr.predict(dataset.X_test)\n",
    "print(classification_report(dataset.y_test, y_pred_logr, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.79      0.76       556\n",
      "         1.0       0.73      0.66      0.70       490\n",
      "\n",
      "    accuracy                           0.73      1046\n",
      "   macro avg       0.73      0.73      0.73      1046\n",
      "weighted avg       0.73      0.73      0.73      1046\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ofurman/Study/counterfactuals/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlpc = MLPClassifier((128, 64), max_iter=50)\n",
    "mlpc.fit(dataset.X_train, dataset.y_train)\n",
    "y_pred_mlpc = mlpc.predict(dataset.X_test)\n",
    "print(classification_report(dataset.y_test, y_pred_mlpc, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_cfs_pred = cf.predict_model(Xs_cfs)\n",
    "ys_orig_pred = cf.predict_model(dataset.X_test[:100])\n",
    "\n",
    "validity(ys_cfs_pred, ys_orig_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cfs_pred_logr = logr.predict(Xs_cfs)\n",
    "y_orig_pred_logr = logr.predict(dataset.X_test[:100])\n",
    "\n",
    "validity(y_cfs_pred_logr, y_orig_pred_logr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cfs_pred_mlpc = mlpc.predict(Xs_cfs)\n",
    "y_orig_pred_mlpc = mlpc.predict(dataset.X_test[:100])\n",
    "\n",
    "np.sum(y_cfs_pred_mlpc != y_orig_pred_mlpc) / y_orig_pred_mlpc.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LawDataset(file_path=\"../data/origin/law.csv\")\n",
    "train_dataloader = dataset.train_dataloader(batch_size=64, shuffle=True)\n",
    "test_dataloader = dataset.test_dataloader(batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   3%|▎         | 3/100 [00:00<00:09, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train: 9.223700612783432, test: 8.432320356369019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  13%|█▎        | 13/100 [00:01<00:08, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train: -1.1231051646173, test: -1.1089640259742737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  23%|██▎       | 23/100 [00:02<00:07, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train: -1.1938231848180294, test: -1.150842159986496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  33%|███▎      | 33/100 [00:03<00:06, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train: -1.2223271373659372, test: -1.1551081836223602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  43%|████▎     | 43/100 [00:04<00:05, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train: -1.224856872111559, test: -1.1615441739559174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  53%|█████▎    | 53/100 [00:05<00:04, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train: -1.219818040728569, test: -1.1669879257678986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  63%|██████▎   | 63/100 [00:06<00:03, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Train: -1.2211038935929537, test: -1.1531431078910828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  73%|███████▎  | 73/100 [00:07<00:02, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Train: -1.2277605552226305, test: -1.1732704937458038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  83%|████████▎ | 83/100 [00:08<00:01, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Train: -1.2253996096551418, test: -1.1545093953609467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  93%|█████████▎| 93/100 [00:09<00:00, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Train: -1.2172787114977837, test: -1.1657378375530243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 100/100 [00:09<00:00, 10.31it/s]\n"
     ]
    }
   ],
   "source": [
    "flow = MaskedAutoregressiveFlow(features=3, hidden_features=4, context_features=1)\n",
    "cf = ApproachThree(model=flow)\n",
    "cf.train_model(\n",
    "    train_loader=train_dataloader,\n",
    "    test_loader=test_dataloader,\n",
    "    epochs=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.79      0.73       107\n",
      "         1.0       0.77      0.66      0.71       115\n",
      "\n",
      "    accuracy                           0.72       222\n",
      "   macro avg       0.73      0.72      0.72       222\n",
      "weighted avg       0.73      0.72      0.72       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf.test_model(test_loader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:46,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "Xs_cfs = cf.generate_counterfactuals(Xs=dataset.X_test[:100], ys=dataset.y_test[:100], num_epochs=100, lr=0.005, alpha=20, beta=0.01)\n",
    "Xs_cfs = torch.concat(Xs_cfs).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.79      0.73       107\n",
      "         1.0       0.77      0.66      0.71       115\n",
      "\n",
      "    accuracy                           0.72       222\n",
      "   macro avg       0.73      0.72      0.72       222\n",
      "weighted avg       0.73      0.72      0.72       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logr = LogisticRegression()\n",
    "logr.fit(dataset.X_train, dataset.y_train)\n",
    "y_pred_logr = logr.predict(dataset.X_test)\n",
    "print(classification_report(dataset.y_test, y_pred_logr, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.80      0.74       107\n",
      "         1.0       0.78      0.65      0.71       115\n",
      "\n",
      "    accuracy                           0.73       222\n",
      "   macro avg       0.73      0.73      0.72       222\n",
      "weighted avg       0.73      0.73      0.72       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlpc = MLPClassifier((128, 64), max_iter=50)\n",
    "mlpc.fit(dataset.X_train, dataset.y_train)\n",
    "y_pred_mlpc = mlpc.predict(dataset.X_test)\n",
    "print(classification_report(dataset.y_test, y_pred_mlpc, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_cfs_pred = cf.predict_model(Xs_cfs)\n",
    "ys_orig_pred = cf.predict_model(dataset.X_test[:100])\n",
    "\n",
    "validity(ys_cfs_pred, ys_orig_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cfs_pred_logr = logr.predict(Xs_cfs)\n",
    "y_orig_pred_logr = logr.predict(dataset.X_test[:100])\n",
    "\n",
    "validity(y_cfs_pred_logr, y_orig_pred_logr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cfs_pred_mlpc = mlpc.predict(Xs_cfs)\n",
    "y_orig_pred_mlpc = mlpc.predict(dataset.X_test[:100])\n",
    "\n",
    "np.sum(y_cfs_pred_mlpc != y_orig_pred_mlpc) / y_orig_pred_mlpc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
