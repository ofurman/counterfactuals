{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.flows import MaskedAutoregressiveFlow\n",
    "\n",
    "from counterfactuals.datasets.heloc import HelocDataset\n",
    "from counterfactuals.datasets.moons import MoonsDataset\n",
    "from counterfactuals.datasets.law import LawDataset\n",
    "\n",
    "from counterfactuals.optimizers.approach_three import ApproachThree\n",
    "\n",
    "from counterfactuals.metrics.metrics import (\n",
    "    perc_valid_cf,\n",
    "    perc_valid_actionable_cf,\n",
    "    continuous_distance,\n",
    "    categorical_distance,\n",
    "    distance_l2_jaccard,\n",
    "    distance_mad_hamming,\n",
    "    plausibility\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MoonsDataset(file_path=\"../data/origin/moons.csv\")\n",
    "train_dataloader = dataset.train_dataloader(batch_size=64, shuffle=True)\n",
    "test_dataloader = dataset.test_dataloader(batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = MaskedAutoregressiveFlow(features=2, hidden_features=4, context_features=1)\n",
    "cf = ApproachThree(model=flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   1%|          | 1/100 [00:00<01:34,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train: 2.137614494794375, test: 1.3597031143995433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  11%|█         | 11/100 [00:09<01:17,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train: 0.41150157308423674, test: 0.38359851791308475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  21%|██        | 21/100 [00:18<01:07,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train: 0.40108432875567185, test: 0.3619806365324901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  31%|███       | 31/100 [00:26<00:59,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train: 0.3979361236934022, test: 0.36750917595166427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  41%|████      | 41/100 [00:35<00:51,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train: 0.3808381977406415, test: 0.35256346143209016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  51%|█████     | 51/100 [00:44<00:42,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train: 0.372011189143379, test: 0.3399317545386461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  61%|██████    | 61/100 [00:53<00:34,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Train: 0.36521152268240464, test: 0.3489550810593825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  71%|███████   | 71/100 [01:01<00:25,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Train: 0.3724483215770164, test: 0.3610877887560771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  81%|████████  | 81/100 [01:10<00:17,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Train: 0.35964421695703036, test: 0.3326881854579999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  91%|█████████ | 91/100 [01:19<00:08,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Train: 0.3594414833691213, test: 0.34789229241701275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 100/100 [01:27<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "cf.train_model(\n",
    "    train_loader=train_dataloader,\n",
    "    test_loader=test_dataloader,\n",
    "    epochs=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       797\n",
      "         1.0       1.00      1.00      1.00       842\n",
      "\n",
      "    accuracy                           1.00      1639\n",
      "   macro avg       1.00      1.00      1.00      1639\n",
      "weighted avg       1.00      1.00      1.00      1639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf.test_model(test_loader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:01,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "Xs_cfs = cf.generate_counterfactuals(Xs=dataset.X_test[:100], ys=dataset.y_test[:100], num_epochs=100, lr=0.005, alpha=20, beta=0.01)\n",
    "Xs_cfs = torch.concat(Xs_cfs).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CF Metrics for Flow predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid_cf': 0.82, 'valid_cf_for_orig_data': 0.82}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_cfs_pred = cf.predict_model(Xs_cfs)\n",
    "ys_orig_pred = cf.predict_model(dataset.X_test[:100])\n",
    "ys_orig = dataset.y_test[:100].flatten()\n",
    "\n",
    "{\n",
    "    \"valid_cf\": perc_valid_cf(ys_orig_pred, y_cf=ys_cfs_pred),\n",
    "    \"valid_cf_for_orig_data\": perc_valid_cf(ys_orig, y_cf=ys_cfs_pred),\n",
    "    # \"perc_valid_actionable_cf\": perc_valid_actionable_cf(X=dataset.X_test, X_cf=Xs_cfs, y=ys_orig_pred, y_cf=ys_cfs_pred, actionable_features=[0])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ofurman/Study/counterfactuals/venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ofurman/Study/counterfactuals/venv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "dataset = HelocDataset(file_path=\"../data/origin/heloc.csv\")\n",
    "train_dataloader = dataset.train_dataloader(batch_size=64, shuffle=True)\n",
    "test_dataloader = dataset.test_dataloader(batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   1%|          | 1/100 [00:00<00:59,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train: 35.74931222985725, test: -4.211443018387346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  11%|█         | 11/100 [00:06<00:53,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train: -24.643653470116693, test: -24.520546296063593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  21%|██        | 21/100 [00:12<00:47,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train: -26.38850231428404, test: -26.427336300120633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  31%|███       | 31/100 [00:18<00:40,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train: -27.363692399617786, test: -27.42388691621668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  41%|████      | 41/100 [00:24<00:34,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train: -27.833121402843577, test: -27.008918537813074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  51%|█████     | 51/100 [00:30<00:29,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train: -28.66521644592285, test: -28.458062115837546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  61%|██████    | 61/100 [00:36<00:22,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Train: -29.34364401327597, test: -29.277825636022232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  71%|███████   | 71/100 [00:42<00:17,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Train: -30.06408018679232, test: -30.155681161319507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  81%|████████  | 81/100 [00:48<00:11,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Train: -31.760069228507376, test: -31.770806032068588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  91%|█████████ | 91/100 [00:53<00:05,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Train: -33.34506137951, test: -33.29686523886288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 100/100 [00:59<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "flow = MaskedAutoregressiveFlow(features=23, hidden_features=4, context_features=1)\n",
    "cf = ApproachThree(model=flow)\n",
    "cf.train_model(\n",
    "    train_loader=train_dataloader,\n",
    "    test_loader=test_dataloader,\n",
    "    epochs=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.60      0.65       556\n",
      "         1.0       0.61      0.72      0.66       490\n",
      "\n",
      "    accuracy                           0.66      1046\n",
      "   macro avg       0.66      0.66      0.66      1046\n",
      "weighted avg       0.66      0.66      0.66      1046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf.test_model(test_loader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:01,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "Xs_cfs = cf.generate_counterfactuals(Xs=dataset.X_test[:100], ys=dataset.y_test[:100], num_epochs=100, lr=0.005, alpha=20, beta=0.01)\n",
    "Xs_cfs = torch.concat(Xs_cfs).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid_cf': 0.65,\n",
       " 'valid_cf_for_orig_data': 1.0,\n",
       " 'perc_valid_actionable_cf': 0.0,\n",
       " 'cont_dist': 1.9591286355257034,\n",
       " 'cat_dist': 0.65,\n",
       " 'distance_l2_jaccard': 0.17664673292815372,\n",
       " 'distance_mad_hamming': 0.5723472670886827,\n",
       " 'plausibility': 0.8041791783208432}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.X_test[:100]\n",
    "ys_cfs_pred = cf.predict_model(Xs_cfs)\n",
    "ys_orig_pred = cf.predict_model(dataset.X_test[:100])\n",
    "ys_orig = dataset.y_test[:100].flatten()\n",
    "\n",
    "{\n",
    "    \"valid_cf\": perc_valid_cf(ys_orig_pred, y_cf=ys_cfs_pred),\n",
    "    \"valid_cf_for_orig_data\": perc_valid_cf(ys_orig, y_cf=ys_cfs_pred),\n",
    "    \"perc_valid_actionable_cf\": perc_valid_actionable_cf(X=dataset.X_test[:100], X_cf=Xs_cfs, y=ys_orig_pred, y_cf=ys_cfs_pred, actionable_features=[1,2]),\n",
    "    \"cont_dist\": continuous_distance(X=X, X_cf=Xs_cfs, continuous_features=[0,1,2,3], metric='mad', X_all=dataset.X_test),\n",
    "    \"cat_dist\": categorical_distance(X=X, X_cf=Xs_cfs, categorical_features=[4,5,6,7,8,9], metric='jaccard', agg='mean'),\n",
    "    \"distance_l2_jaccard\": distance_l2_jaccard(X=X, X_cf=Xs_cfs, continuous_features=[0,1,2,3], categorical_features=[4,5,6,7,8,9]),\n",
    "    \"distance_mad_hamming\": distance_mad_hamming(X=X, X_cf=Xs_cfs, continuous_features=[0,1,2,3], categorical_features=[4,5,6,7,8,9], X_all=X, agg='mean'),\n",
    "    \"plausibility\": plausibility(X, Xs_cfs, ys_orig, continuous_features_all=[0,1,2,3], categorical_features_all=[4,5,6,7,8,9], X_train=dataset.X_train, ratio_cont=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LawDataset(file_path=\"../data/origin/law.csv\")\n",
    "train_dataloader = dataset.train_dataloader(batch_size=64, shuffle=True)\n",
    "test_dataloader = dataset.test_dataloader(batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   3%|▎         | 3/100 [00:00<00:09, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train: 9.223700612783432, test: 8.432320356369019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  13%|█▎        | 13/100 [00:01<00:08, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train: -1.1231051646173, test: -1.1089640259742737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  23%|██▎       | 23/100 [00:02<00:07, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train: -1.1938231848180294, test: -1.150842159986496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  33%|███▎      | 33/100 [00:03<00:06, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train: -1.2223271373659372, test: -1.1551081836223602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  43%|████▎     | 43/100 [00:04<00:05, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train: -1.224856872111559, test: -1.1615441739559174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  53%|█████▎    | 53/100 [00:05<00:04, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train: -1.219818040728569, test: -1.1669879257678986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  63%|██████▎   | 63/100 [00:06<00:03, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Train: -1.2211038935929537, test: -1.1531431078910828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  73%|███████▎  | 73/100 [00:07<00:02, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Train: -1.2277605552226305, test: -1.1732704937458038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  83%|████████▎ | 83/100 [00:08<00:01, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Train: -1.2253996096551418, test: -1.1545093953609467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  93%|█████████▎| 93/100 [00:09<00:00, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Train: -1.2172787114977837, test: -1.1657378375530243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 100/100 [00:09<00:00, 10.31it/s]\n"
     ]
    }
   ],
   "source": [
    "flow = MaskedAutoregressiveFlow(features=3, hidden_features=4, context_features=1)\n",
    "cf = ApproachThree(model=flow)\n",
    "cf.train_model(\n",
    "    train_loader=train_dataloader,\n",
    "    test_loader=test_dataloader,\n",
    "    epochs=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.79      0.73       107\n",
      "         1.0       0.77      0.66      0.71       115\n",
      "\n",
      "    accuracy                           0.72       222\n",
      "   macro avg       0.73      0.72      0.72       222\n",
      "weighted avg       0.73      0.72      0.72       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf.test_model(test_loader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:46,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "Xs_cfs = cf.generate_counterfactuals(Xs=dataset.X_test[:100], ys=dataset.y_test[:100], num_epochs=100, lr=0.005, alpha=20, beta=0.01)\n",
    "Xs_cfs = torch.concat(Xs_cfs).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.79      0.73       107\n",
      "         1.0       0.77      0.66      0.71       115\n",
      "\n",
      "    accuracy                           0.72       222\n",
      "   macro avg       0.73      0.72      0.72       222\n",
      "weighted avg       0.73      0.72      0.72       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logr = LogisticRegression()\n",
    "logr.fit(dataset.X_train, dataset.y_train)\n",
    "y_pred_logr = logr.predict(dataset.X_test)\n",
    "print(classification_report(dataset.y_test, y_pred_logr, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.80      0.74       107\n",
      "         1.0       0.78      0.65      0.71       115\n",
      "\n",
      "    accuracy                           0.73       222\n",
      "   macro avg       0.73      0.73      0.72       222\n",
      "weighted avg       0.73      0.73      0.72       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlpc = MLPClassifier((128, 64), max_iter=50)\n",
    "mlpc.fit(dataset.X_train, dataset.y_train)\n",
    "y_pred_mlpc = mlpc.predict(dataset.X_test)\n",
    "print(classification_report(dataset.y_test, y_pred_mlpc, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_cfs_pred = cf.predict_model(Xs_cfs)\n",
    "ys_orig_pred = cf.predict_model(dataset.X_test[:100])\n",
    "\n",
    "validity(ys_cfs_pred, ys_orig_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cfs_pred_logr = logr.predict(Xs_cfs)\n",
    "y_orig_pred_logr = logr.predict(dataset.X_test[:100])\n",
    "\n",
    "validity(y_cfs_pred_logr, y_orig_pred_logr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cfs_pred_mlpc = mlpc.predict(Xs_cfs)\n",
    "y_orig_pred_mlpc = mlpc.predict(dataset.X_test[:100])\n",
    "\n",
    "np.sum(y_cfs_pred_mlpc != y_orig_pred_mlpc) / y_orig_pred_mlpc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
