{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62f27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba5827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ofurman/pwr/counterfactuals/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from cel.cf_methods import PPCEF\n",
    "from cel.datasets.file_dataset import FileDataset\n",
    "from cel.losses import BinaryDiscLoss\n",
    "from cel.metrics.metrics import evaluate_cf\n",
    "from cel.models import LogisticRegression, MaskedAutoregressiveFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7846df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "dataset = FileDataset(config_path=\"../config/datasets/moons.yaml\")\n",
    "# dataset = AdultDataset()\n",
    "\n",
    "# Get the split data that's already available\n",
    "X_train = dataset.X_train\n",
    "X_test = dataset.X_test\n",
    "y_train = dataset.y_train\n",
    "y_test = dataset.y_test\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.float32),\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80491016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2244, Train: 0.2591, test: 0.2769, patience: 600:  22%|██▏       | 2244/10000 [00:05<00:19, 389.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train a discriminative model\n",
    "num_inputs = X_train.shape[1]\n",
    "num_targets = 1\n",
    "\n",
    "discrimaiative_model = LogisticRegression(\n",
    "    num_inputs=num_inputs,\n",
    "    num_targets=num_targets,\n",
    ")\n",
    "discrimaiative_model.fit(train_dataloader, test_dataloader, epochs=10000, patience=600, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3adbe920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2225, Train: 0.3243, test: 0.4486, patience: 600:  22%|██▏       | 2225/10000 [00:41<02:25, 53.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train a generative model\n",
    "num_inputs = X_train.shape[1]\n",
    "num_targets = 1\n",
    "\n",
    "generative_model = MaskedAutoregressiveFlow(\n",
    "    features=num_inputs,\n",
    "    hidden_features=128,\n",
    "    context_features=num_targets,\n",
    ")\n",
    "generative_model.fit(train_dataloader, test_dataloader, epochs=10000, patience=600, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41bf0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_threshold = np.median(generative_model.predict_log_prob(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7670b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator loss: 0.0000, Prob loss: 0.2344: 100%|██████████| 10000/10000 [00:32<00:00, 307.03it/s]\n"
     ]
    }
   ],
   "source": [
    "cf_method = PPCEF(\n",
    "    disc_model=discrimaiative_model,\n",
    "    gen_model=generative_model,\n",
    "    disc_model_criterion=BinaryDiscLoss(),\n",
    ")\n",
    "\n",
    "results = cf_method.explain_dataloader(\n",
    "    test_dataloader,\n",
    "    alpha=100,\n",
    "    log_prob_threshold=log_prob_threshold,\n",
    "    epochs=10000,\n",
    "    patience=600,\n",
    "    lr=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "802fa0fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mevaluate_cf\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdisc_model\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdiscrimaiative_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgen_model\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgenerative_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX_cf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m.\u001B[49m\u001B[43mx_cfs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_returned\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mones_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m.\u001B[49m\u001B[43mx_cfs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcontinuous_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnumerical_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcategorical_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcategorical_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmedian_log_prob\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlog_prob_threshold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m=\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m=\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/pwr/counterfactuals/counterfactuals/metrics/metrics.py:394\u001B[39m, in \u001B[36mevaluate_cf\u001B[39m\u001B[34m(disc_model, gen_model, X_cf, model_returned, continuous_features, categorical_features, X_train, y_train, X_test, y_test, median_log_prob, y_target)\u001B[39m\n\u001B[32m    378\u001B[39m y_target = y_target.numpy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(y_target, torch.Tensor) \u001B[38;5;28;01melse\u001B[39;00m y_target\n\u001B[32m    380\u001B[39m metrics_cf = CFMetrics(\n\u001B[32m    381\u001B[39m     disc_model=disc_model,\n\u001B[32m    382\u001B[39m     gen_model=gen_model,\n\u001B[32m   (...)\u001B[39m\u001B[32m    392\u001B[39m     prob_plausibility_threshold=median_log_prob,\n\u001B[32m    393\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m394\u001B[39m metrics = \u001B[43mmetrics_cf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcalc_all_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    395\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m metrics\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/pwr/counterfactuals/counterfactuals/metrics/metrics.py:325\u001B[39m, in \u001B[36mCFMetrics.calc_all_metrics\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    316\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcalc_all_metrics\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> \u001B[38;5;28mdict\u001B[39m:\n\u001B[32m    317\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    318\u001B[39m \u001B[33;03m    Calculate all metrics.\u001B[39;00m\n\u001B[32m    319\u001B[39m \n\u001B[32m    320\u001B[39m \u001B[33;03m    Returns:\u001B[39;00m\n\u001B[32m    321\u001B[39m \u001B[33;03m        dict: Dictionary of metric names and values.\u001B[39;00m\n\u001B[32m    322\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    323\u001B[39m     metrics = {\n\u001B[32m    324\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mcoverage\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.coverage(),\n\u001B[32m--> \u001B[39m\u001B[32m325\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mvalidity\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mvalidity\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    326\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mactionability\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.actionability(),\n\u001B[32m    327\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33msparsity\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.sparsity(),\n\u001B[32m    328\u001B[39m         \u001B[38;5;66;03m# \"target_distance\": self.target_distance(),\u001B[39;00m\n\u001B[32m    329\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mproximity_categorical_hamming\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.feature_distance(\n\u001B[32m    330\u001B[39m             categorical_metric=\u001B[33m\"\u001B[39m\u001B[33mhamming\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    331\u001B[39m         ),\n\u001B[32m    332\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mproximity_categorical_jaccard\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.feature_distance(\n\u001B[32m    333\u001B[39m             categorical_metric=\u001B[33m\"\u001B[39m\u001B[33mjaccard\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    334\u001B[39m         ),\n\u001B[32m    335\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mproximity_continuous_manhattan\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.feature_distance(\n\u001B[32m    336\u001B[39m             continuous_metric=\u001B[33m\"\u001B[39m\u001B[33mcityblock\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    337\u001B[39m         ),\n\u001B[32m    338\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mproximity_continuous_euclidean\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.feature_distance(\n\u001B[32m    339\u001B[39m             continuous_metric=\u001B[33m\"\u001B[39m\u001B[33meuclidean\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    340\u001B[39m         ),\n\u001B[32m    341\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mproximity_continuous_mad\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.feature_distance(\n\u001B[32m    342\u001B[39m             continuous_metric=\u001B[33m\"\u001B[39m\u001B[33mmad\u001B[39m\u001B[33m\"\u001B[39m, X_train=\u001B[38;5;28mself\u001B[39m.X_train\n\u001B[32m    343\u001B[39m         ),\n\u001B[32m    344\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mproximity_l2_jaccard\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.feature_distance(\n\u001B[32m    345\u001B[39m             continuous_metric=\u001B[33m\"\u001B[39m\u001B[33meuclidean\u001B[39m\u001B[33m\"\u001B[39m, categorical_metric=\u001B[33m\"\u001B[39m\u001B[33mjaccard\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    346\u001B[39m         ),\n\u001B[32m    347\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mproximity_mad_hamming\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.feature_distance(\n\u001B[32m    348\u001B[39m             continuous_metric=\u001B[33m\"\u001B[39m\u001B[33mmad\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    349\u001B[39m             categorical_metric=\u001B[33m\"\u001B[39m\u001B[33mhamming\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    350\u001B[39m             X_train=\u001B[38;5;28mself\u001B[39m.X_train,\n\u001B[32m    351\u001B[39m         ),\n\u001B[32m    352\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mprob_plausibility\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.prob_plausibility(cf=\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m    353\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mlog_density_cf\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.log_density(cf=\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m    354\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mlog_density_test\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.log_density(cf=\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[32m    355\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mlof_scores_cf\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.lof_scores(cf=\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m    356\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mlof_scores_test\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.lof_scores(cf=\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[32m    357\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33misolation_forest_scores_cf\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.isolation_forest_scores(cf=\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m    358\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33misolation_forest_scores_test\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.isolation_forest_scores(cf=\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[32m    359\u001B[39m     }\n\u001B[32m    360\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m metrics\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/pwr/counterfactuals/counterfactuals/metrics/metrics.py:138\u001B[39m, in \u001B[36mCFMetrics.validity\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    131\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mvalidity\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> \u001B[38;5;28mfloat\u001B[39m:\n\u001B[32m    132\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    133\u001B[39m \u001B[33;03m    Compute the validity metric.\u001B[39;00m\n\u001B[32m    134\u001B[39m \n\u001B[32m    135\u001B[39m \u001B[33;03m    Returns:\u001B[39;00m\n\u001B[32m    136\u001B[39m \u001B[33;03m        float: Validity metric value.\u001B[39;00m\n\u001B[32m    137\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m138\u001B[39m     y_cf = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdisc_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mX_cf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnumpy\u001B[49m()\n\u001B[32m    139\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (y_cf != \u001B[38;5;28mself\u001B[39m.y_test.squeeze()).mean()\n",
      "\u001B[31mAttributeError\u001B[39m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "evaluate_cf(\n",
    "    disc_model=discrimaiative_model,\n",
    "    gen_model=generative_model,\n",
    "    X_cf=results.x_cfs,\n",
    "    model_returned=np.ones_like(results.x_cfs),\n",
    "    continuous_features=dataset.numerical_features,\n",
    "    categorical_features=dataset.categorical_features,\n",
    "    median_log_prob=log_prob_threshold,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c36f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
