{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62f27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba5827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ofurman/pwr/counterfactuals/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from counterfactuals.cf_methods import PPCEF\n",
    "from counterfactuals.datasets.file_dataset import FileDataset\n",
    "from counterfactuals.losses import BinaryDiscLoss\n",
    "from counterfactuals.metrics.metrics import evaluate_cf\n",
    "from counterfactuals.models import LogisticRegression, MaskedAutoregressiveFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7846df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "dataset = FileDataset(config_path=\"../config/datasets/moons.yaml\")\n",
    "# dataset = AdultDataset()\n",
    "\n",
    "# Get the split data that's already available\n",
    "X_train = dataset.X_train\n",
    "X_test = dataset.X_test\n",
    "y_train = dataset.y_train\n",
    "y_test = dataset.y_test\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.float32),\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80491016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2244, Train: 0.2591, test: 0.2769, patience: 600:  22%|██▏       | 2244/10000 [00:05<00:19, 389.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train a discriminative model\n",
    "num_inputs = X_train.shape[1]\n",
    "num_targets = 1\n",
    "\n",
    "discrimaiative_model = LogisticRegression(\n",
    "    num_inputs=num_inputs,\n",
    "    num_targets=num_targets,\n",
    ")\n",
    "discrimaiative_model.fit(train_dataloader, test_dataloader, epochs=10000, patience=600, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3adbe920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2225, Train: 0.3243, test: 0.4486, patience: 600:  22%|██▏       | 2225/10000 [00:41<02:25, 53.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train a generative model\n",
    "num_inputs = X_train.shape[1]\n",
    "num_targets = 1\n",
    "\n",
    "generative_model = MaskedAutoregressiveFlow(\n",
    "    features=num_inputs,\n",
    "    hidden_features=128,\n",
    "    context_features=num_targets,\n",
    ")\n",
    "generative_model.fit(train_dataloader, test_dataloader, epochs=10000, patience=600, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41bf0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_threshold = np.median(generative_model.predict_log_prob(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7670b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discriminator loss: 0.0000, Prob loss: 0.2344: 100%|██████████| 10000/10000 [00:32<00:00, 307.03it/s]\n"
     ]
    }
   ],
   "source": [
    "cf_method = PPCEF(\n",
    "    disc_model=discrimaiative_model,\n",
    "    gen_model=generative_model,\n",
    "    disc_model_criterion=BinaryDiscLoss(),\n",
    ")\n",
    "\n",
    "results = cf_method.explain_dataloader(\n",
    "    test_dataloader,\n",
    "    alpha=100,\n",
    "    log_prob_threshold=log_prob_threshold,\n",
    "    epochs=10000,\n",
    "    patience=600,\n",
    "    lr=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "802fa0fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate_cf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisc_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiscrimaiative_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgen_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerative_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_cf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx_cfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_returned\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx_cfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontinuous_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumerical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmedian_log_prob\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_prob_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pwr/counterfactuals/counterfactuals/metrics/metrics.py:394\u001b[39m, in \u001b[36mevaluate_cf\u001b[39m\u001b[34m(disc_model, gen_model, X_cf, model_returned, continuous_features, categorical_features, X_train, y_train, X_test, y_test, median_log_prob, y_target)\u001b[39m\n\u001b[32m    378\u001b[39m y_target = y_target.numpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_target, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m y_target\n\u001b[32m    380\u001b[39m metrics_cf = CFMetrics(\n\u001b[32m    381\u001b[39m     disc_model=disc_model,\n\u001b[32m    382\u001b[39m     gen_model=gen_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    392\u001b[39m     prob_plausibility_threshold=median_log_prob,\n\u001b[32m    393\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m metrics = \u001b[43mmetrics_cf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalc_all_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pwr/counterfactuals/counterfactuals/metrics/metrics.py:325\u001b[39m, in \u001b[36mCFMetrics.calc_all_metrics\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalc_all_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m    317\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[33;03m    Calculate all metrics.\u001b[39;00m\n\u001b[32m    319\u001b[39m \n\u001b[32m    320\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m        dict: Dictionary of metric names and values.\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    323\u001b[39m     metrics = {\n\u001b[32m    324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcoverage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.coverage(),\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mvalidity\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    326\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mactionability\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.actionability(),\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msparsity\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.sparsity(),\n\u001b[32m    328\u001b[39m         \u001b[38;5;66;03m# \"target_distance\": self.target_distance(),\u001b[39;00m\n\u001b[32m    329\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mproximity_categorical_hamming\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.feature_distance(\n\u001b[32m    330\u001b[39m             categorical_metric=\u001b[33m\"\u001b[39m\u001b[33mhamming\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    331\u001b[39m         ),\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mproximity_categorical_jaccard\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.feature_distance(\n\u001b[32m    333\u001b[39m             categorical_metric=\u001b[33m\"\u001b[39m\u001b[33mjaccard\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    334\u001b[39m         ),\n\u001b[32m    335\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mproximity_continuous_manhattan\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.feature_distance(\n\u001b[32m    336\u001b[39m             continuous_metric=\u001b[33m\"\u001b[39m\u001b[33mcityblock\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    337\u001b[39m         ),\n\u001b[32m    338\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mproximity_continuous_euclidean\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.feature_distance(\n\u001b[32m    339\u001b[39m             continuous_metric=\u001b[33m\"\u001b[39m\u001b[33meuclidean\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         ),\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mproximity_continuous_mad\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.feature_distance(\n\u001b[32m    342\u001b[39m             continuous_metric=\u001b[33m\"\u001b[39m\u001b[33mmad\u001b[39m\u001b[33m\"\u001b[39m, X_train=\u001b[38;5;28mself\u001b[39m.X_train\n\u001b[32m    343\u001b[39m         ),\n\u001b[32m    344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mproximity_l2_jaccard\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.feature_distance(\n\u001b[32m    345\u001b[39m             continuous_metric=\u001b[33m\"\u001b[39m\u001b[33meuclidean\u001b[39m\u001b[33m\"\u001b[39m, categorical_metric=\u001b[33m\"\u001b[39m\u001b[33mjaccard\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    346\u001b[39m         ),\n\u001b[32m    347\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mproximity_mad_hamming\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.feature_distance(\n\u001b[32m    348\u001b[39m             continuous_metric=\u001b[33m\"\u001b[39m\u001b[33mmad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    349\u001b[39m             categorical_metric=\u001b[33m\"\u001b[39m\u001b[33mhamming\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    350\u001b[39m             X_train=\u001b[38;5;28mself\u001b[39m.X_train,\n\u001b[32m    351\u001b[39m         ),\n\u001b[32m    352\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprob_plausibility\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.prob_plausibility(cf=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    353\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlog_density_cf\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.log_density(cf=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    354\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlog_density_test\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.log_density(cf=\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m    355\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlof_scores_cf\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.lof_scores(cf=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    356\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlof_scores_test\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.lof_scores(cf=\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m    357\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33misolation_forest_scores_cf\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.isolation_forest_scores(cf=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    358\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33misolation_forest_scores_test\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.isolation_forest_scores(cf=\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m    359\u001b[39m     }\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pwr/counterfactuals/counterfactuals/metrics/metrics.py:138\u001b[39m, in \u001b[36mCFMetrics.validity\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidity\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m    132\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    Compute the validity metric.\u001b[39;00m\n\u001b[32m    134\u001b[39m \n\u001b[32m    135\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m        float: Validity metric value.\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     y_cf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdisc_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_cf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m()\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (y_cf != \u001b[38;5;28mself\u001b[39m.y_test.squeeze()).mean()\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "evaluate_cf(\n",
    "    disc_model=discrimaiative_model,\n",
    "    gen_model=generative_model,\n",
    "    X_cf=results.x_cfs,\n",
    "    model_returned=np.ones_like(results.x_cfs),\n",
    "    continuous_features=dataset.numerical_features,\n",
    "    categorical_features=dataset.categorical_features,\n",
    "    median_log_prob=log_prob_threshold,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c36f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
